{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사용 데이터 경로  \n",
    "C:\\Users\\ChoiSeongHyeon\\Desktop\\Dataset\\UOS\\BearingType_DeepGrooveBall\\SamplingRate_16000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MATLAB 파일의 키 목록:\n",
      "- __header__: <class 'bytes'>\n",
      "  값: b'MATLAB 5.0 MAT-file, Platform: PCWIN64, Created on: Wed Jun  5 10:40:04 2024'\n",
      "- __version__: <class 'str'>\n",
      "  값: 1.0\n",
      "- __globals__: <class 'list'>\n",
      "  샘플 데이터: []\n",
      "- Data: <class 'numpy.ndarray'>\n",
      "  데이터 형상(shape): (1280000, 1)\n",
      "- STFTFreq: <class 'numpy.ndarray'>\n",
      "  데이터 형상(shape): (128, 1)\n",
      "- STFTTime: <class 'numpy.ndarray'>\n",
      "  데이터 형상(shape): (1, 128)\n",
      "- Spectrogram: <class 'numpy.ndarray'>\n",
      "  데이터 형상(shape): (78, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "\n",
    "# MATLAB 파일 경로\n",
    "file_path = r\"C:\\Users\\ChoiSeongHyeon\\Desktop\\Dataset\\UOS\\BearingType_DeepGrooveBall\\SamplingRate_16000\\RotatingSpeed_1000\\H_B_16_6204_1000.mat\"\n",
    "\n",
    "def print_mat_contents(file_path):\n",
    "    try:\n",
    "        # MATLAB 파일 로드\n",
    "        mat_contents = scipy.io.loadmat(file_path)\n",
    "        \n",
    "        # MATLAB 파일 내용 출력\n",
    "        print(\"MATLAB 파일의 키 목록:\")\n",
    "        for key in mat_contents.keys():\n",
    "            # 내부 데이터 구조를 확인하기 위해 데이터의 타입과 샘플 출력\n",
    "            print(f\"- {key}: {type(mat_contents[key])}\")\n",
    "            if isinstance(mat_contents[key], (list, dict, tuple)):\n",
    "                print(f\"  샘플 데이터: {mat_contents[key][:2]}\")\n",
    "            elif hasattr(mat_contents[key], 'shape'):\n",
    "                print(f\"  데이터 형상(shape): {mat_contents[key].shape}\")\n",
    "            else:\n",
    "                print(f\"  값: {mat_contents[key]}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"MATLAB 파일을 읽는 중 오류가 발생했습니다: {e}\")\n",
    "\n",
    "# 함수 실행\n",
    "print_mat_contents(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 1. 데이터 Sampling  \n",
    "- Origin Data -> Test, Validation, Train (6:2:2)로 구분\n",
    "- SAMPLE_SIZE : 2,048, SHIFT_SIZE : 1,024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Origin 파일의 길이 : 1280,000  \n",
    "Shift Size : 1024  \n",
    "따라서, 1,250개의 샘플 생성되어야 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install scipy numpy tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing H: 100%|██████████| 6/6 [00:45<00:00,  7.61s/it]\n",
      "Processing B: 100%|██████████| 6/6 [00:55<00:00,  9.20s/it]\n",
      "Processing IR: 100%|██████████| 6/6 [00:51<00:00,  8.58s/it]\n",
      "Processing OR: 100%|██████████| 6/6 [00:48<00:00,  8.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 모든 데이터 처리가 완료되었습니다!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 기본 경로 설정\n",
    "BASE_DIR = r\"C:\\Users\\ChoiSeongHyeon\\Desktop\\WinningT\\Winning Ticket\\MyWinningTicket\\Dataset\\UOS\"\n",
    "FAULT_TYPES = [\"H\", \"B\", \"IR\", \"OR\"]\n",
    "SPLIT_RATIOS = (0.6, 0.2, 0.2)  # Train: 60%, Val: 20%, Test: 20%\n",
    "SAMPLE_SIZE = 2048\n",
    "SHIFT_SIZE = 1024\n",
    "\n",
    "def load_mat_file(file_path):\n",
    "    \"\"\" .mat 파일에서 'Data' 키를 가진 데이터를 불러옴 \"\"\"\n",
    "    mat_data = scipy.io.loadmat(file_path)\n",
    "    if 'Data' in mat_data:\n",
    "        return mat_data['Data'].flatten()  # 1D 배열로 변환\n",
    "    else:\n",
    "        raise KeyError(f\"'Data' key not found in {file_path}\")\n",
    "\n",
    "def split_data(data, split_ratios):\n",
    "    \"\"\" 데이터를 Train, Validation, Test로 분할 \"\"\"\n",
    "    total_len = len(data)\n",
    "    train_end = int(total_len * split_ratios[0])\n",
    "    val_end = train_end + int(total_len * split_ratios[1])\n",
    "\n",
    "    train_data = data[:train_end]\n",
    "    val_data = data[train_end:val_end]\n",
    "    test_data = data[val_end:]\n",
    "\n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "def save_csv_file(file_path, data):\n",
    "    \"\"\" 데이터를 CSV 파일로 저장 (단일 열 형태) \"\"\"\n",
    "    df = pd.DataFrame(data)  # ✅ 단일 열(column) 형태로 변환\n",
    "    df.to_csv(file_path, index=False, header=False)  # ✅ 열 이름 없이 저장\n",
    "\n",
    "def create_samples(data, save_dir, base_filename):\n",
    "    \"\"\" 데이터를 2048 크기로 1024씩 이동하며 개별 CSV 파일로 저장 \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    num_samples = int((len(data) / SHIFT_SIZE) - 1)\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        start = i * SHIFT_SIZE\n",
    "        end = start + SAMPLE_SIZE\n",
    "        if end > len(data):  \n",
    "            break\n",
    "\n",
    "        sample = data[start:end]\n",
    "        sample_filename = os.path.join(save_dir, f\"{base_filename}_{i+1}.csv\")\n",
    "        save_csv_file(sample_filename, sample)\n",
    "\n",
    "def process_fault_type(fault_type):\n",
    "    \"\"\" 각 Fault Type 폴더의 파일을 처리 \"\"\"\n",
    "    fault_dir = os.path.join(BASE_DIR, fault_type, \"Origin\")\n",
    "    split_dir = os.path.join(BASE_DIR, fault_type, \"Train_Val_Test_Split\")\n",
    "    samples_dir = os.path.join(BASE_DIR, fault_type, \"Samples\")\n",
    "\n",
    "    os.makedirs(split_dir, exist_ok=True)\n",
    "    os.makedirs(samples_dir, exist_ok=True)\n",
    "\n",
    "    # Origin 폴더 내 모든 .mat 파일 처리\n",
    "    for file in tqdm(os.listdir(fault_dir), desc=f\"Processing {fault_type}\"):\n",
    "        if not file.endswith(\".mat\"):\n",
    "            continue\n",
    "\n",
    "        file_path = os.path.join(fault_dir, file)\n",
    "        base_name = file.replace(\".mat\", \"\")\n",
    "\n",
    "        try:\n",
    "            # .mat 파일 로드\n",
    "            data = load_mat_file(file_path)\n",
    "            \n",
    "            # Train, Validation, Test 데이터 분할\n",
    "            train_data, val_data, test_data = split_data(data, SPLIT_RATIOS)\n",
    "\n",
    "            # Train, Validation, Test 데이터를 CSV 파일로 저장\n",
    "            save_csv_file(os.path.join(split_dir, f\"{base_name}_Train.csv\"), train_data)\n",
    "            save_csv_file(os.path.join(split_dir, f\"{base_name}_Validation.csv\"), val_data)\n",
    "            save_csv_file(os.path.join(split_dir, f\"{base_name}_Test.csv\"), test_data)\n",
    "\n",
    "            # Train, Validation, Test 데이터에서 개별 샘플 생성 및 저장\n",
    "            create_samples(train_data, samples_dir, f\"{base_name}_Train\")\n",
    "            create_samples(val_data, samples_dir, f\"{base_name}_Validation\")\n",
    "            create_samples(test_data, samples_dir, f\"{base_name}_Test\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file}: {e}\")\n",
    "\n",
    "# 모든 Fault Type에 대해 실행\n",
    "for fault in FAULT_TYPES:\n",
    "    process_fault_type(fault)\n",
    "\n",
    "print(\"✅ 모든 데이터 처리가 완료되었습니다!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Rotating Speed에 상관없이 Train Data로 섞기!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 2. Labelling  \n",
    "H : 0, IR : 1, OR : 2, B : 3  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 3. WDCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
